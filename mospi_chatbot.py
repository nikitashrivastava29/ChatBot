# -*- coding: utf-8 -*-
"""MoSPI_ChatBot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jhmRpj88qSRn_OUg8bA3w2WfEd5X2leG
"""

!pip install -Uqqq pip --progress-bar off
!pip install -qqq langchain==0.0.141 --progress-bar off
!pip install -qqq openai==0.27.4 --progress-bar off
!pip install -Uqqq watermark==2.3.1 --progress-bar off
!pip install -Uqqq chromadb==0.3.21 --progress-bar off
!pip install -Uqqq tiktoken==0.3.3 --progress-bar off
!pip install -Uqqq youtube-transcript-api==0.5.0 --progress-bar off
!pip install -Uqqq pytube==12.1.3 --progress-bar off
!pip install -Uqqq unstructured[local-inference]==0.5.12 --pro

import os
import textwrap

import chromadb
import langchain
import openai
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import TextLoader, UnstructuredPDFLoader, YoutubeLoader
from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings
from langchain.indexes import VectorstoreIndexCreator
from langchain.llms import OpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma

# Commented out IPython magic to ensure Python compatibility.
# %load_ext watermark
# %watermark --iversions -v -m

def print_response(response: str):
    print("\n".join(textwrap.wrap(response, width=100)))

os.environ["OPENAI_API_KEY"] = "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"

!gdown 1eetuan04uj9-QKu_Vok2mbSK23G0H7yN
!gdown 1MVIhlCJS5RjVDy_s93Jb4vkHt6jAmgaa

!pip install -Uqqq unstructured[local-inference]==0.5.12 --pro

!pip install unstructured

pdf_loader = UnstructuredPDFLoader("./FAQ-CC05072023.pdf")
pdf_pages = pdf_loader.load_and_split()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=64)
texts = text_splitter.split_documents(pdf_pages)
len(texts)

len(texts[0].page_content), len(texts[1].page_content)

texts[0]

MODEL_NAME = "sentence-transformers/all-mpnet-base-v2"
hf_embeddings = HuggingFaceEmbeddings(model_name=MODEL_NAME)

text = texts[0].page_content
text

hf_embedding = hf_embeddings.embed_documents([text])
len(hf_embedding[0])

embeddings = OpenAIEmbeddings()

openai_embedding = embeddings.embed_documents([text])
len(openai_embedding[0])

db = Chroma.from_documents(texts, embeddings)

PERSIST_DIRECTORY = "db"

db = Chroma.from_documents(
    documents=texts, embedding=embeddings, persist_directory=PERSIST_DIRECTORY
)

db.persist()

vectordb = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)

chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(temperature=0),
    chain_type="stuff",
    retriever=db.as_retriever(search_kwargs={"k": 2}),
)

query= "How is CPI calculated?"
chain.run(query)

!pip install streamlit

import streamlit as st

st.title("Query your Documents")
prompt= st.text_input("Enter you Questions regarding the Document")
if prompt:
  response=  chain.run(prompt)
  st.write("<br><i>" + response+ "</i><hr>", unsafe_allow_html=True)